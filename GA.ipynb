{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cccfe13d-feb0-449b-815f-47022ee48fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested (50,), relu, adam => MSE: 3.5335765639845995\n",
      "Tested (50,), relu, sgd => MSE: 1.038277552584494\n",
      "Tested (50,), tanh, adam => MSE: 1.117501595654189\n",
      "Tested (50,), tanh, sgd => MSE: 0.9794951097048008\n",
      "Tested (100,), relu, adam => MSE: 3.462557072357153\n",
      "Tested (100,), relu, sgd => MSE: 0.9966727195740722\n",
      "Tested (100,), tanh, adam => MSE: 0.9316728673660731\n",
      "Tested (100,), tanh, sgd => MSE: 0.9503517147628835\n",
      "Tested (50, 50), relu, adam => MSE: 1.1009668508223676\n",
      "Tested (50, 50), relu, sgd => MSE: 0.9389666217503263\n",
      "Tested (50, 50), tanh, adam => MSE: 1.9042674149156453\n",
      "Tested (50, 50), tanh, sgd => MSE: 0.9741193263887072\n",
      "\n",
      "Best parameters found:\n",
      "Hidden Layer Sizes: (100,)\n",
      "Activation: tanh\n",
      "Solver: adam\n",
      "Validation Error (MSE): 0.9316728673660731\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(42)\n",
    "num_samples = 1000\n",
    "num_features = 5\n",
    "X = np.random.rand(num_samples, num_features)\n",
    "true_coefficients = np.random.rand(num_features) * 10\n",
    "noise = np.random.normal(loc=0, scale=1, size=num_samples)\n",
    "y = np.dot(X, true_coefficients) + noise\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data (important for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Define a function to train and evaluate the neural network\n",
    "def train_neural_network(hidden_layer_sizes, activation, solver):\n",
    "    model = MLPRegressor(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    error = mean_squared_error(y_val, y_pred)\n",
    "    return error\n",
    "\n",
    "# Manually test different hyperparameters\n",
    "best_error = float('inf')\n",
    "best_params = None\n",
    "\n",
    "# Try different configurations\n",
    "hidden_layer_sizes_options = [(50,), (100,), (50, 50)]\n",
    "activation_options = ['relu', 'tanh']\n",
    "solver_options = ['adam', 'sgd']\n",
    "\n",
    "for hidden_layer_sizes in hidden_layer_sizes_options:\n",
    "    for activation in activation_options:\n",
    "        for solver in solver_options:\n",
    "            error = train_neural_network(hidden_layer_sizes, activation, solver)\n",
    "            print(f\"Tested {hidden_layer_sizes}, {activation}, {solver} => MSE: {error}\")\n",
    "            if error < best_error:\n",
    "                best_error = error\n",
    "                best_params = (hidden_layer_sizes, activation, solver)\n",
    "\n",
    "print(\"\\nBest parameters found:\")\n",
    "print(f\"Hidden Layer Sizes: {best_params[0]}\")\n",
    "print(f\"Activation: {best_params[1]}\")\n",
    "print(f\"Solver: {best_params[2]}\")\n",
    "print(f\"Validation Error (MSE): {best_error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3dbbb46-e62f-4a1c-af44-2b0ddb7d6cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 1, MSE: 4.4953\n",
      "Gen 2, MSE: 4.3959\n",
      "Gen 3, MSE: 4.3556\n",
      "Gen 4, MSE: 4.2915\n",
      "Gen 5, MSE: 4.2915\n",
      "Gen 6, MSE: 4.2766\n",
      "Gen 7, MSE: 4.2766\n",
      "Gen 8, MSE: 4.2393\n",
      "Gen 9, MSE: 4.2308\n",
      "Gen 10, MSE: 4.1749\n",
      "Test MSE: 2.6147542088566462\n"
     ]
    }
   ],
   "source": [
    "#MK optimal mse should be less than 4\n",
    "\n",
    "import numpy as np, random\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(42)\n",
    "X = (np.random.uniform(150, 200, (100, 3)) - 175) / 25\n",
    "y = 0.3*X[:,0] - 0.2*X[:,1] + 0.1*X[:,2] + np.random.normal(0, 2, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "def create_nn(params):\n",
    "    m = MLPRegressor(hidden_layer_sizes=(5,), max_iter=2, solver='lbfgs', warm_start=True)\n",
    "\n",
    "    m.fit(X_train, y_train)\n",
    "    p = np.array(params); i = 0\n",
    "    for arr in m.coefs_ + m.intercepts_:\n",
    "        s = np.prod(arr.shape)\n",
    "        arr[...] = p[i:i+s].reshape(arr.shape)\n",
    "        i += s\n",
    "    return m\n",
    "\n",
    "def fitness(p): return mean_squared_error(y_train, create_nn(p).predict(X_train))\n",
    "def crossover(p1, p2): pt = random.randint(0, len(p1)-1); return p1[:pt]+p2[pt:]\n",
    "def mutate(p, r=0.1): return [w+np.random.randn()*r if random.random()<0.1 else w for w in p]\n",
    "\n",
    "tmp = MLPRegressor(hidden_layer_sizes=(5,), max_iter=1); tmp.fit(X_train, y_train)\n",
    "n_params = sum(np.prod(a.shape) for a in tmp.coefs_ + tmp.intercepts_)\n",
    "pop = [np.random.uniform(-1, 1, n_params).tolist() for _ in range(10)]\n",
    "\n",
    "for g in range(10):\n",
    "    pop = sorted(pop, key=fitness)\n",
    "    new_pop = pop[:2]\n",
    "    while len(new_pop) < len(pop):\n",
    "        c = mutate(crossover(*random.sample(pop[:5], 2)))\n",
    "        new_pop.append(c)\n",
    "    pop = new_pop\n",
    "    print(f\"Gen {g+1}, MSE: {fitness(pop[0]):.4f}\")\n",
    "\n",
    "best = pop[0]\n",
    "print(\"Test MSE:\", mean_squared_error(y_test, create_nn(best).predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b78dbb5d-797e-4325-b07b-d6c5b8911be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 1, MSE: 837.9926\n",
      "Gen 2, MSE: 879.3118\n",
      "Gen 3, MSE: 899.3248\n",
      "Gen 4, MSE: 213.4704\n",
      "Gen 5, MSE: 155.7211\n",
      "Gen 6, MSE: 100.6344\n",
      "Gen 7, MSE: 83.3831\n",
      "Gen 8, MSE: 86.6404\n",
      "Gen 9, MSE: 88.8074\n",
      "Gen 10, MSE: 76.7427\n",
      "Test MSE: 60.076637048881345\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Simulated spray drying dataset: [InletTemp, FeedRate, AtomSpeed] -> MoistureContent\n",
    "np.random.seed(42)\n",
    "X = np.random.uniform(low=150, high=200, size=(100, 3))  # features\n",
    "y = 0.3*X[:,0] - 0.2*X[:,1] + 0.1*X[:,2] + np.random.normal(0, 2, 100)  # target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Neural Network Model (MLP)\n",
    "def create_nn(weights):\n",
    "    model = MLPRegressor(hidden_layer_sizes=(5,), max_iter=1, warm_start=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    weights = np.array(weights)  # <-- convert to NumPy array\n",
    "    i = 0\n",
    "    for layer_weights in model.coefs_:\n",
    "        shape = layer_weights.shape\n",
    "        model.coefs_[i] = weights[:np.prod(shape)].reshape(shape)\n",
    "        weights = weights[np.prod(shape):]\n",
    "        i += 1\n",
    "    return model\n",
    "\n",
    "# Genetic Algorithm\n",
    "def fitness_function(weights):\n",
    "    model = create_nn(weights)\n",
    "    preds = model.predict(X_train)\n",
    "    return mean_squared_error(y_train, preds)\n",
    "\n",
    "def crossover(p1, p2):\n",
    "    point = random.randint(0, len(p1)-1)\n",
    "    return p1[:point] + p2[point:]\n",
    "\n",
    "def mutate(ind, rate=0.1):\n",
    "    return [w + np.random.randn()*rate if random.random() < 0.1 else w for w in ind]\n",
    "\n",
    "# Initialize population\n",
    "n_weights = (3*5) + (5*1)  # assuming 3 input, 5 hidden, 1 output\n",
    "pop = [np.random.uniform(-1, 1, n_weights).tolist() for _ in range(10)]\n",
    "\n",
    "# Run GA\n",
    "for generation in range(10):\n",
    "    pop = sorted(pop, key=fitness_function)\n",
    "    new_pop = pop[:2]  # elitism\n",
    "    while len(new_pop) < len(pop):\n",
    "        p1, p2 = random.sample(pop[:5], 2)\n",
    "        child = mutate(crossover(p1, p2))\n",
    "        new_pop.append(child)\n",
    "    pop = new_pop\n",
    "    print(f\"Gen {generation+1}, MSE: {fitness_function(pop[0]):.4f}\")\n",
    "\n",
    "# Final model\n",
    "best_weights = pop[0]\n",
    "final_model = create_nn(best_weights)\n",
    "test_preds = final_model.predict(X_test)\n",
    "print(\"Test MSE:\", mean_squared_error(y_test, test_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5393af5d-d155-465f-94a0-43ad8ac82e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
